# Senior Editor Comments to Authors

I have now received the reviewers' reports and a recommendation from the
Associate Editor who handled the review process of your resubmission. Copies of
their reports are included below. Based on their evaluations, I regret to
inform you that we are unable to publish your paper in Methods in Ecology and
Evolution in its current form.

However, we would be willing to consider another resubmission, which takes into
consideration the new feedback you have received. You will see that several
comments really ask for a structural rework towards the core of the
"Perspective" format of MEE, which is about the stimulation of scientific debate
and the offer of conceptual advances. While the ms is giving some of that, it
does not convince readers and reviewers even after 2 reviews.

I think that reframing how it is presented would go a long way to appeal to
readers and current & future users of graph embedding. It is not usual for us to
offer the possibility to resubmit after a first "reject and resubmit" decision
when the reviews are of that extent and we did so because of there is a
potential for the ms to have all these comments (mentioned below) addressed. A
new version including all these (numerous) comments would still need much work
but would really allow the ms to be a useful roadmap towards predicting metaweb
(even if that means going above the word limit).

In addition, there are several comments from the previous round that were not
addressed but still created issues with the second revision; dealing with them
and using the additional perspective of this new revision will help move the ms
forward.

# Associate Editor Comments to Authors

(There are no comments.)

# Reviewer 3 Comments to Authors

## General comments

The manuscript is a resubmission of a previous version that I did not review nor
see. I understand that the manuscript is proposed for publication under the
"Perspective" type in MEE. Besides the current version, I had access to the
first reports and the authors' answers.

> We thank the reviewer for the obvious effort they put in their comments. We do
> also want to express concern (which we will do more explicitly in the
> following responses) that what the comments are about is often unclear; it has
> been sometimes difficult for us to understand whether the reviewer was
> expressing criticism about the revised manuscript, our previous set of
> responses, or even previously published manuscripts from this working group.
> Nevertheless, we have done our best to take the comments at face value and
> address them in depth in the revision, whenever they were about the current
> submission.

I think that the contents of this Perspective manuscript do not - as required by
the journal guidelines - "stimulate [much] scientific debate". Neither does it
significantly "offer conceptual advances or opinions or identify gaps". I'll now
try to motivate this opinion.

> We think this criticism is unfair, as we had already outlined in the responses
> how the *original submission* introduced novel ideas, and notably identified
> knowledge/methodological gaps.

In their answers, the authors "point out that the submitted version of this
present manuscript includes" 3 different elements. It is unclear to me whether
they consider this to be the complete list of the manuscript contributions.

> This specific comment in the *initial responses* was intended to highlight
> areas that were already in the *original submission*, specifically areas that
> constitute the "advances to the scientific debate" the reviewer asked for in
> their previous point. We would like to note that a description of what the
> *current submission* includes is given in the abstract of the *current
> submission*. Furthermore, we are unsure as to what the intent of this comment
> is. As the reviewer has not formulated actionable critiques about the
> manuscript (such as, for example, identification of areas where a better
> description of what the manuscript brings is required), no changes were made.

Anyway, let me discuss the first of these elements. It is "an overview of
embedding techniques and their application to species interaction networks". I
do not agree with this first claim. In my opinion, Table 1 that lists a large
number of graph embedding techniques is not sufficient to be considered an
overview.

> We have edited the text to clarify that the take-home message from this table
> is that a large number of these methods have *not* been applied to species
> interactions networks, and clarified which have been applied to biological
> associations (without being about biotic interactions *per se*).

The authors barely address the difference between nodes embedding and graph
embedding: while I can clearly see the second column of the table, the text does
not contain any sentence that could help a reader not familiar with these
embedding techniques to learn about this major difference.

> We have added a description of the difference (and overlap) between the
> categories of embeddings to the main text, as well as in the table.

The text is even misleading when (line 75) the authors say that "Their [the
graph embedding techniques] main goal is to learn a low dimensional vector
representations for the nodes of the graph (embeddings)".

> We fail to see how the text is misleading, and would like to point out that
> the reviewer has not substantiated this claim. No changes were made.

An overview of embedding techniques should go beyond a list of references and
come with (at least some lines of) an introduction to the methods and their main
differences.

> We would like to clarify that the purpose of this paper is to point out that a
> family of methods (embedding) has been under-used in the study of ecological
> networks, despite their potential usefulness to be related to additional data
> for transfer learning. What the reviewer suggests is a review or benchmark on
> each of the methods, which is outside the scope of a perspective manuscript,
> and more suitable for a review. This is written in the introduction of the
> *current submission*.

Going back to the manuscript contributions, the end of the paper's introduction
(from lines 37 to 40), sets a slightly different list: "In this contribution, we
highlight the power in viewing (and constructing) metawebs as probabilistic
objects in the context of rare interactions, discuss how a family of machine
learning tools (graph embeddings and transfer learning) can be used to overcome
data limitations to metaweb inference, and highlight how the use of metawebs
introduces important questions for the field of network ecology." From this, I
understand that the 3 elements pointed out by the authors in their answer do not
constitute the core of their contribution, which is rather described by these
previous lines. This leads me to my next remark.

> This comment is purely a consequence of the reviewer, with all due respect,
> over-interpreting the responses to the editor and using them as the basis for
> critiques of the *re-submitted manuscript*. From this point onwards, it is
> difficult for us to decide what the reviewer is actually discussing. For the
> sake of clarity, let us re-state the manuscript "mission statement": viewing
> metawebs as probabilistic objects is likely to be very fruitful for their
> prediction and study, and coupling graph embeddings with transfer learning is
> a promising way forward. This is the last paragraph of the introduction in
> plain English; no changes made.

The previous reports raised the concern that the current manuscript "adds little
to the previous published paper". The authors answered that "there is not a
single instance where areas of overlap are clearly identified". I do identify
specific places that support the reports concern:

The contents of the paper as described at the end of the introduction match the
ideas underlying the previous published work;

> We re-read both manuscripts in full, and the only "overlap" that we could find
> (keeping in mind that the end of the introduction of the *re-submitted
> version* was modified following comments in the previous round of review) is
> that some of the same general ideas are discussed; this is unavoidable in
> order to convey some of the foundational ideas that justify the use of
> embeddings coupled to transfer learning: the existence of conserved backbones,
> invariants, or action of phylogenetic/trait-based processes.

Section "Graph embedding offers promises for the inference of potential
interactions" is not only "an overview of embedding techniques" but rather it is
biased towards "their application to species interaction networks", which is the
topic of the previous published paper.

> This is correct; it is, in fact, stated as early as the title of the
> manuscript. Again, this comment is based on the *responses to reviewers* from
> the previous round, and has no actionable items related to the *current
> version* of the manuscript. The point of the *current submission* is to
> provide a higher level *perspective* on the topic, of which the *previously
> published paper* was a specific case-study.

Graph embedding techniques are promising for ecological networks, obviously not
only in the context of inferring a metaweb. This leads us back to the main
concern with this paragraph: that the authors do not even have a sentence about
the major difference between node embeddings and whole graphs embeddings shows
that they are not interested in these techniques for ecological networks in
general.

> We would like to thank the reviewer for introducing some levity in the review
> process; our writing of an entire manuscript on the embeddings (and transfer
> learning) should be obvious proof of our genuine interest in the topic. We
> have added some text to clarify the difference between different types of
> embedding, and would have greatly appreciated if the editor had weighed-in
> against base accusations against the sincerity of our interest for a topic we
> have been working on for several years.

Figure 1 is titled "Overview of the embedding process", which describes only
part A and B so half of the scheme. The remainder is concerned with the method
from the previously published paper.

> The last part of this comment is untrue; the figure describes a general cycle
> of input/embedding/transfer/inference, with specific mentions of potential
> predictors to learn the embedding. This comment is, once again, coming
> dreadfully close to serious allegations of self-plagiarism, which frankly make
> us question the neutrality of the reviewer in this matter. We have changed the
> title of the figure.

The third element of the list pointed out by the authors in their answer is "a
discussion of the remaining technical and methodological challenges associated
with this approach". Here I understood that "this" refers to "prediction through
embeddings" and the title of the last section ( "The metaweb embeds both
ecological hypotheses and practices") is slightly misleading as its contents are
rather biased towards inference of a metaweb (after its embedding).

> This is, again, a comment on the *responses to reviewers*, which requires no
> change to the *current submission*.

For the authors (line 172) "The first open research problem is the taxonomic and
spatial limit of the metaweb to embed and transfer" and (line 189) "The second
series of problems relate to determining which area should be used to infer the
new metaweb". These two points could have formed a perspective in the previous
published paper.

> We wholeheartedly agree, but they had to be cut to adhere to space
> constraints. No changes requested, no changes made.

The last part (from line 203, "praxis of ecological research") opens to more
general considerations but again contains specific remarks related to their
previous work: "Applying any embedding to biased data does not debias them"
(line 206); "the need to appraise and correct biases that are unwittingly
propagated to algorithms when embedded" (line 215).

> This statement is egregious (and false). The ideas contained in this paragraph
> have no relationship to our previous work, and this should be obvious by
> examining the literature cited. The fragments of text cherry-picked by the
> reviewer are not ideas we claim credit for; they are important notions for
> practitioners of ML to consider at all times. No changes made to the
> manuscript.

The second element of the list pointed out by the authors in their answer is "a
discussion of the properties of metawebs that make them amenable to prediction
through embeddings". I did not clearly identify which part of the manuscript
corresponds to that element. I can only suppose that this refers to the
paragraph that "a metaweb is an inherently probabilistic object", but as far as
I understand, the paragraph does not make a clear link between these properties
and the amenability to prediction through embedding.

> This is, again, a comment on the *responses to reviewers*; we hope that the
> changes we made in response to reviewer's 5 very constructive comments on the
> text of the actual manuscript have adequately addressed it.

While I am convinced that "a metaweb is an inherently probabilistic object" and
found interesting the part of the manuscript between lines 42 to 57, I did not
understand how this is combined with the second half of this section (namely
that "high quality observational data" can be combined "with synthetic data
coming from predictive models" to "increase the volume of information available
for inference"). More precisely, that `[the metaweb] fixes an upper bound on
which interactions can exist' is not clearly improved by a probabilistic version
of this metaweb.

> This section has been modified following comments from other reviewers,
> specifically by addressing the status of documents v. undocumented
> interactions, and how probabilities outputted by predictive models can help
> bridge the gap.

The manuscript points the need for the construction of metawebs at large spatial
and taxonomic scales. The authors are not specific about what "large" is
exactly. It would be interesting to be more specific on that or provide some
examples. Is this a world-wide scale? A continental scale? Any scale for which
aggregation of local data is necessary? Anything else? Line 192 (and below)
appears the mention of "country level"; However countries are too heterogeneous
in their sizes to answer my point. Also, the term 'continental scale' appears on
line 217 but in a specific sentence and I am not convinced that this is exactly
what the authors have in mind when mentioning "large" scales.

> This has been addressed in the discussion, by expanding the second-to-last
> paragraph.

The abstract contains the sentence (point 4) "[we] discuss how the choice of the
species pool has consequences on the reconstructed network". This is indeed an
interesting question. But I did not see anything in the text that could refer to
this.

> See response above.

## Minor comments

line 10: "accurate predictors are important for accurate predictions". Indeed,
but what is your point?

> Our point is given in plain English immediately after the comma: "the lack of
> methods that can leverage a small amount of *accurate* data is a serious
> impediment to our predictive ability".

line 13: replace GBIF and UICN by the full names.

> Fixed.

line 73: "Graph (or Network) embedding (fig. 1)". You should modify the
reference to "fig1. A, B" because the rest of the figure is not part of the
embedding process. By the way, the caption of figure 1 "Overview of the
embedding process" is also misleading as (again) this title only describes half
of the scheme.

> As the manuscript is about embeddings *and* transfer, we feel like the
> reference to the figure is appropriate here. This is, specifically, because
> the *embedding* is learned by the transfer model, and therefore the entire
> figure is dealing with embedded networks. No changes made.

I understand that the paragraph on GNN (from line 88) was added to answer a
referee concern, but it is disproportionate: you use as much space not to speak
about GNN as to speak about (ML) graph embeddings.

> We added this paragraph in response to comments from a reviewer, and we agreed
> with the original point raised by the reviewer, specifically that readers may
> be curious about GNNs; no changes made.

I understand that the illustration of metaweb embedding was added to answer one
of the referees of the first round. Nonetheless, I do not see the added value of
it.

> We hope that the expansion of this illustration will make its added value
> clearer. See responses to the other reviewers for more details.

On line 147, the authors claim to see "an inflection point around 25
dimensions". I do not see any inflection, but I understand this is a reasonable
compromise.

> We have expanded the illustration, and now use the finite differences methods
> to identify the inflection point.

line 219: "Particularly on Turtle Island and other territories". I did not
understand why in a very general paragraph you refer "particularly" to this
specific example. Maybe "for example" would be more suited.

> No changes made.

# Reviewer 4 Comments to Authors

## General comments

The paper summarized the key challenges of inferring metawebs based on graph
embedding approaches. It also highlighted the significant advantages of using
graph embedding and transfer learning techniques for species interaction network
prediction and other ecological problem applications. The paper provided a very
important research direction of applying advanced graph embedding and transfer
learning to tackle diverse inference tasks for species interaction networks.

> We thank the reviewer for their kind words.

Two main questions about this paper are listed below.

Fig.1 is a good diagram that shows the whole pipeline with the input graph
adjacency matrix, output graph embedding and combined with transfer learning
technique. I would also suggest the authors to include some experimental results
based on graph embedding and transfer learning for specie interaction inference
with real dataset.

> We have greatly expanded the illustration, and as a result have split it into
> two components: one showing the more statistical considerations, and the other
> showing the ecological ones.

Please update the article information for the paper (Xu, M.. Understanding graph
embedding methods and their applications. SIAM Review, 2021) in the reference
section.

> Thank you - we now cite the published version rather than the version on
> arxiv.

# Reviewer 5 Comments to Authors

## General comments

This manuscript consists in a revised version (re-submission) of a perspective
paper dedicated to the potential contribution of graph embedding to metaweb
prediction.

The authors provided a pedagogical illustration on a host-parasites system,
aiming at predicting (in a probabilistic way) the links of this bipartite
network using Random Dot Product Graph embedding. This illustration implements
key elements of Fig. 1 and might invite the reader to use or develop the
embedding framework on various datasets. The figure showing the decrease of the
loss with the rank of the embedding is particularly welcome since it shows to
what extent network structure can be reasonably summarised in few dimensions
using a specific embedding.

> We would like to thank the reviewer for pointing out that the rapid decrease
> in $L_2$ loss is a good thing; we have added this information to the
> description of the case study, and further clarified this point by presenting
> the $L_2$ loss (for interaction/pairwise level quality) and the cumulative
> variance explained (for network-level quality), as a pre-requisite for an
> ecological interpretation. We had to split the figure in two following further
> points by the reviewer, which resulted in new information.

However, I got a bit surprised not to find the ecological interpretation of this
embedding in terms of response and effects traits. I think the authors should
better try to link ecological theory in general and ecological hypothesis
associated with machine learning methods throughout the manuscript. I understand
that the manuscript is centered on methods to predict metawebs with somehow
incomplete sampling or knowledge. Consequently, as many research papers on
applied machine learning in ecology, ecological hypothesis and theory are a bit
behind the scene.

> This is a fair point, we thank the reviewer for bringing up this concern; we
> have added a paragraph to the section on embeddings, to explain why we do not
> think the values outputted by the models *are* traits. To summarize: they are
> not directly related, as causes or consequences, to organismal fitness. This
> does not prevent their use in predictive settings (indeed, we have clarified
> this at several places in the text), but it would be problematic to assume
> that they are "functional" traits. We think that *latent values* is a more
> appropriate descriptor.

I think that a perspective paper should clarify possible ecological
interpretation of machine learning methods. If the manuscript is clear and
enlightening on the probabilistic metaweb approach, ecological hypothesis
associated to link predictions are much more obscure. The following points
should be somehow addressed in the manuscript to get additional perspectives:

What are the interpretations of Random Dot Product Graph embeddings in terms of
latent traits?

> In addition to the paragraph we added in response to the previous point, we
> have decided to split the illustration figure in two, in order to show how the
> position of species in the embedding sub-space relate to ecological
> information. Specifically, we extracted body mass information from PanTHERIA,
> and show that the position of hosts alongside the first (main) dimension of
> the embedding is predictive of parasite richness, but not of body mass; we
> also tie this result to existing literature.

What are the hypothesis behind link prediction using other information (traits,
phylogeny as in Strydom et al 2022)?

> We thank the reviewer for asking this important clarification; we have greatly
> expanded the section on the use of node metadata to clarify which hypotheses
> are associated to broad families of predictors, alongside references to
> published literature showing that importance of these predictors. We would
> like to point out that doing so goes beyond the scope of the previously
> published paper, and is a more general overview of 'picking the right
> predictor for the right hypothesis', up to and including hypothesis testing.
> This is now additionally reflected in the conceptual figure, which separates
> ecologically relevant predictors from the rest of the latent variables used in
> the process.

What structures are considered in the different embeddings? Table 1 mentions
several embedding techniques and separates node from graph embedding. However,
even two node embeddings algorithm can have different interpretations. For
example, tsne is based on neighbor (local structure) whereas node2vec relies on
random walks, so paths in the network (global structure). Both could be
interpreted in ecological terms.

> This is an important clarification to request, and we thank the reviewer for
> bringing it up. The strength of embeddings is that they are robust to network
> structure *and* remove the need to know specific information about the network
> beforehand. We have added this information in the section of embeddings, but
> also discuss it (with new references to the literature) in the specific
> context of RDPG in the illustration.

Predicting metawebs with these two methods do not hold the same hypothesis on
species interactions. How does it affect potential applications? I think Table 1
must be enriched more (maybe add a figure or split it) in order to be a roadmap
and not simply a catalog. It should mix and bridge embeddings, ecological
interpretations and even some illustrations to guide the reader in this machine
learning jungle. Such clarification should be also present in the manuscript

> We have pointed out in the text, in a few places, that examining the "best"
> embedding method for a given problem is important; this is coming from
> existing literature. One issue with what the reviewer suggests is that the
> embedding techniques are not always easy to map onto ecological
> considerations. This is a good thing; indeed, this is because these techniques
> have been developed for general problems on graphs, and ecological networks
> are very likely to fall within the range of graphs that these methods will
> handle (in fact, this is demonstrated by the references in the table,
> specifically the column on applications). We thing that one way this table can
> serve as a roadmap is by putting more emphasis on what has *not* been done,
> *i.e.* the majority of embedding techniques have not been applied to species
> interaction networks. We have updated the legend of the table to make this
> point stand out more.

To what extent co-occurence data should be considered in embedding approaches?
Co-occurence is considered for statistical association networks but probably not
in the same manner than the deep learning model of (Strydom et al 2021). So, to
what extent co-occurence data can be used to predict interaction? Table 1
mentions statistical association methods and JSDM. The authors should be more
clear in Table 1 and in the manuscript on the link/differences between
association methods (that predicts associations from co-occurence) and link
prediction using embeddings. The term statistical association is present in
Table 1 but not in the text, it can be quite confusing for the reader.

> We have clarified this point in the table, by explaining that some methods
> have been used for network-like problems, without being applied to species
> interaction networks data. We also touch upon the issue of co-occurrence in
> the illustration, and have added references highlighting why co-occurrence
> alone is not a good predictor to the introduction. Nevertheless, it *can* be
> added to the predictor data, and we have updated the conceptual figure in this
> way.

I think this manuscript could be considered for publication in Methods in
Ecology and Evolution but it must offer broader perspectives than Strydom et al.
To do so, the authors should try to address somehow the previous listed points.

> We thank the reviewer for their encouraging words, and for the suggestions
> that led to the revision of the illustration. We hope that the revised version
> will meet their expectations.

## Minor comments

L20: Local networks capture alpha-diversity of interactions but also beta
diversity since interactions from the metaweb can be absent from local networks
species absence.

> This is correct, but does not seem relevant to the paragraph; no changes were
> made.

L24: Yes, I agree that Saravia et al. 2021 shows that local network structure
(represented by network metrics blind to species identity) does not differ from
the one expected from a null model (Trophic Theory of Island Food webs).
However, the manuscript focuses on alpha-diversity metrics. In terms of species
and interaction composition, they can still differ even if they have more or
less the same structure. It think this point should be clarified. Indeed,
otherwise, it somehow states that we do not need to focus on local composition
since local networks have the same structure as the metaweb.

> This is correct, and we addressed this point in the original submission, in
> the next paragraph (which is focused on backbones of networks). No changes
> were made.

L63: Does it “generate” or uncover the core rules associated to species
interactions? I do not really understand the point of “generating rules”. For
me, statistical methods try, using abstract representations, to
uncover/formulate biological rules.

> This is a good point, and we thank the reviewer for pointing it out. We have
> rephrased this sentence to clarify that observational data are used for the
> inference of rules, and that the resulting augmented dataset is used for
> analysis.

L79: Yes, embedding methods can exhibit structural invariants in ecological
networks. However, what characteristics of the networks should be considered in
the model (links,paths,motifs...)?

> This is an interesting point; we would like to apologize, first, for the lack
> of clarity, as we were talking about structural invariant in *networks*, not
> in their embeddings. We have clarified the paragraph. Second; the invariants
> in structure are not necessarily revealed by the usual network measures, but
> are indeed *structural*, *i.e.* they can be seen through the shape of the
> network. We have clarified the paragraph to make it clearer that the lower
> dimensions of an embedding should capture these invariants, and improved the
> transition to the work of Eklof et al. showing the low-dimensionality of food
> webs.

L83: If the choice of the embedding matters for the result, why not providing to
the reader some sort of roadmap of these embeddings techniques for different
applications?

> The literature suggests that the algorithm should be selected on a
> problem-specific basis, and we have changed the paragraph to reflect this. The
> table has been changed in response to other comments.

L85: For the moment, Table 1 is more a catalog than a roadmap.

> This is correct -- we are unsure where the notion of a "roadmap" comes from,
> as we label the table an "overview", and never claim that the table can serve
> as a roadmap. Nevertheless, we are confident that there is value in the table
> as it is, as our survey of methods revealed that a number of them have not
> been used in network ecology; indeed, a number of references in the table are
> network-adjacent, as they describe the use of embeddings for JSDMs or
> statistical associations. In keeping with the response to the previous comment
> (the need for a case-by-base appraisal of embedding techniques), this is
> particularly problematic; we have edited the caption of the table to reflect
> this.

L86: Ok, here comes different network representations (latent traits or random
walks). How do we interpret these methods in ecological terms? Which one is the
most suitable in the various potential applications.

> As we have mentioned in other places in the manuscript, this is
> context-dependent, and existing literature suggests that one should explore
> different embedding techniques.

L99: Bohan et al. 2017 mentions several associations methods to build networks.
If I am correct, these associations methods are not mentioned in the manuscript.
The authors must clarify this point.

> The methods in Bohan et al. are not based on embedding (and deal with specific
> categories of datasets that are far from widespread anyways); we have not
> edited the manuscript.

L115: The authors should clarify the ecological hypothesis associated to such
approach and the potential limits of predicting interactions using node
metadata.

> We have expanded this paragraph significantly, by explicitly stating what the
> assumptions in using these predictors are, and further by showing how the
> relationship between phylogeny/traits and embeddings can be used in the
> context of testing hypotheses about the structure of networks.

L134: I think this illustration is relevant but it must be enriched in order,
for example, to compare different embedding or incorporating meta-data. To what
extent will different embedding techniques provide different networks? Will the
loss with the rank be similar if you use link (as in the RDGP model) or path
based embedding?

> We have greatly expanded the illustration, notably to bring into consideration
> more ecological elements. The potential to perform the analysis that the
> reviewer suggests is limited by data availability, and would be outside the
> scope of this manuscript.

Moreover, Stochastic Block Model can also but used to perform link predictions
(Gaucher et al. 2019; Link Prediction in the Stochastic Block Model with
Outliers. stat.) and is related to RDGP, I think it deserves a mention here.

> We have added a discussion of this article in the section on metawebs; an
> importantly feature of embeddings is that they do not assume a specific
> structure for the network in order to capture emergent features.

L136: What are the ecological hypothesis associated to RDGP model in terms of
response and effect traits?

> We have addressed this comment by adding a paragraph about the status of
> latent values w.r.t. response/effect traits, which we can summarize as "the
> latent values should not be discussed as functional traits". Furthermore, we
> have added a justification of why RPDG is an interesting embedding technique
> in the first paragraph of the section on the illustration.