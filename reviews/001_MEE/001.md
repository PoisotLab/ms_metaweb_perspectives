# Senior Editor Comments to Authors

This MS is strongly linked to the recently published one in MEE since it was
split from this published one early on. While the links between the 2 obvious,
the present MS should be more clearly independent from the other since the
overall perspective of the reviews is that the ms adds little to the previous
published paper.

> We would like to express our surprise to this comment, since the other article
> was only mentioned twice (in the caption of a figure and in a table).
> Interestingly, this other manuscript is now cited *more* in order to address a
> comment by the first reviewer. To be perfectly transparent about our feelings
> reading the review, we did feel like our manuscript was reviewed with the
> mindest that it was presented as a Research (and not Perspective) article. We
> further felt that we needed to defend ourselves against accusations of
> sensationalism ("marketing"), opportunism, speculation, and general
> sloppyness, coming notably and openly from the second reviewer. We did outline
> how these were unfair, unsubstantiated, and unprofessional, and have done our
> best to have a fair reading of the details comments made by the second
> reviewer; this is more than the courtesy extended to us by this reviewer when
> writing their comments, and we would like to re-state that such reviews can
> have lasting impacts on the morale of early career authors (of which this
> manuscript has many).

In summary, they should be complementary but not overlapping to a large extent.
In the current ms, a strong message yet different from the other paper would be
that graph embedding is an emerging field in machine learning that holds great
potential for ecological problems. And this will certainly affect the whole
structure of the ms.

> We do appreciate this comment, and wholeheartedly agree. Yet, it is extremely
> difficult for us to address, as to the best of our understanding of the two
> reviews and the senior editor comments, there is not a single instance where
> areas of overlap are clearly identified, or indeed identified *at all*.
> Following the comments of reviewer 1, we do hope that the central argument
> ("graph embedding is useful for link prediction") will be clearer.

Adding a section on "how to" approach graph embedding, and a nutshell section on
embedding methods vs dimension reduction method, an example dataset to assess
with a R-code; all these would be essential for the ms even if it coud go over
the word limit. Overall, if these comments are implement together with the
suggestions of the reviewers, the current ms would be completely revamped and
would need a lot of work from the authors. yet it should produce a strong ms and
have potential to influence the field.

# Associate Editor Comments to Authors

(There are no comments.)

# Reviewer 1 Comments to Authors

## General comments

I read this interesting text about the idea of using embeddings to predict
metawebs. I understand that this is a perspective. About 2/3 of the manuscript
is dealing with metawebs (very pleasant to read), and the remaining 1/3
recommend the use of network embeddings (actually, the authors have mixed up
embedding methods and dimension reduction methods, which are actually two
disjoint but connected concepts).

However, I am very suprised that there is no material to support the proposal.
Do the authors already use an embedding techniques on their datasets? They claim
it is promising to use embedding with metawebs, but is it an intuition? or are
there scientifical experiments/analysis/reasoning that could support this idea?

> We would like to reframe our response to this point (and indeed to comments by
> both reviewers) by re-stating that this manuscript is a "Perspective" piece,
> the goal of which is, according to the journal website, "to stimulate
> scientific debate, [by offering] conceptual advances or opinions or identity
> gaps in knowledge". With this established, the table in the original
> manuscript already had a list of embeddings methods applied to species
> interactions predictions, which in our opinion should assuage the concern of
> reviewer 1 by establishing that this is not "an intuition". Furthermore, a
> part of the text discusses recent work from Strydom et al. (2021) wherein
> graph embeddings have been used to not only predict a metaweb, but do so by
> transfering information across space. Despite the fact that these information
> was already in the original manuscript, we have re-worded and expanded a
> number of sections to make them stand out more.

At some point, I am wondering if it would be have been possible to write the
same article replacing "embedding" by "graph neural networks"... These are all
interesting techniques, and I do appreciate that the authors try to help
ecologists to understand them. But we need more facts to understand the
pros/cons of these options. I am afraid the reader can not be convinced reading
the manuscript in its present form.

> This is a good question, which we explored during the writing of the
> manuscript. GNN approaches are comparatively younger than the broader family
> of graph embeddings methods. We have added a rationale for not spending too
> much time on GNN (which would also require to introduce a solid amount of
> literature on deep learning in general), but point readers towards recent
> reviews.

I am sincerely annoyed that I can't be more positive, maybe I missed something,
and I hope that these comments can be used to improve the manuscript. But I do
think this paper is "too light" to be published in MEE.

> We hope that our gentle reminder of the nature of this paper, as a perspective
> piece and not a review, will help assuage the sentiment that the papier is too
> "light". We are confident that the additions to the text are adressing all
> major comments raised by reviewer 1.

## Detailed comments

Until l.68: a very nice introduction about the concept of metaweb

> Thank you.

L.72-83 & Table 1 : here, there is a mixture of graph and node embeddings, i.e.
projecting a graph or a node into a low dimensional space. Would require some
clarifications.

> The second column of the table already specifies whether nodes or graphs (as
> well as sub-graphs, multiple graphs, and node complexes) are embedded given
> the different methods; we are not sure what the reviewer wants to see added as
> a clarification. As the information asked is already given, and absent
> specific feedback, we have not changed the manuscript.

L.91 & Figure 2 : there is another subtlety here. Indeed, embedding is often
followed by a dimension reduction technique (could be PCA, t-SNE).  As in figure
2, section D is for dimension reduction. In my opinion, these are two distinct
concepts, embedding and dimension reduction. For instance, one can perform an
embedding listing a series of metrics, then perform a PCA to obtain a 2-D
representation.

> This is indeed a subtle point, and very respectfully, we think that the
> reviewer's confusion justifies the need for our manuscript. Graph embedding
> and dimensionality reduction are different yet *related* concepts. For
> example, PCA can be used initially to maximise the information in a dataset
> then fed into t-SNE; both the PCA and t-SNE step can be parameterized to
> retain fewer dimensions, but so can neither of them, with the user deciding to
> visualize a two or three dimensional representation. We have added a paragraph
> to make sure this point is extremely clear, and we hope that it will help
> readers decide on the appropriate method to use.

l. 107 : "large confidence intervals during estimation of the values in the
low-rank space" => what does it really mean?

> We have clarified that this would hint at the fact that the two species pools
> are too distinct for transfer learning to work with adequate confidence.

l. 109: "resulting embeddings would have interactions" => same thing. Could you
be less elusive or give references?

> We have clarified that this would lead to higher variance in the original
> dataset compared to the target dataset, leading to too much noise in the
> prediction.

l. 128-141: this part is interesting at some point, but the reader can loose the
point of the article... In particular, mentioning AI here is disconnected to the
remaining text. I understand that embedding methods are part of AI at some
point, but AI gather so many domains....

> We have considerably expanded the last section, to further clarify which
> issues were "research-based" *v.* "praxis-based" problems, alongside possible
> avenues to start adressing these problems. We do hope that this will make the
> point of the last paragraph more obvious.

# Reviewer 2 Comments to Authors

## General comments

This manuscript consists in a perspective on the use of graph embeddings to
infer potential interactions, by using metadata and interaction databases. It
is, somehow, linked to the idea that potential interactions involving a new
species can be predicted from its traits (vulnerability and foraging) and
interactions involving similar species. If such an idea , based on niche
conservatism regarding interactions, is not new (e.g. Desjardins-Proulx et al.
2017, Strydom et al. 2021a), the use of graph embeddings to infer potential
interactions is a useful step forward.

> We agree with this comment; graph embeddings can indeed project networks in a
> space where the detection of unknown interactions is easier, and we support
> this claim with several examples throughout the text.

However, I strongly doubt that such a short and speculative paper helps the
network ecology community.

> We would like to gently, yet very firmly, push back on the idea that the
> manuscript is speculative. It may be forward-looking, or prospective, but much
> every claim we make is either backed by facts (in the forms of reference to
> existing literature in the fields of ecology, machine learning, and
> environmental governance), or accompanied (notably in the last section) by
> suggestions of additional work needed to adress some of the gaps we have
> identified. We think that "speculative" is an unfair assesment of our work,
> and we do hope that it did not affect the reviewer ability to take it
> seriously. We would very specifically point out that table 1 contains examples
> of published research papers using the techniques we discuss, and that the
> text contains discussion of some of these papers. We are therefore confident
> that we clear the bar for "not speculative" by a very broad margin.
> Furthermore, we are confident that the changes made in response to the
> comments by Reviewer 1 will help makew the manuscript more convincing.

Despite being appealing (it mentions the term ‘machine learning’ 10 times), I
think that it contains too much generic wishful thinking to be useful and
implementable.

> We would like to question the intent behind this comment. Is there a threshold
> above which mentioning machine learning too much opens authors to accusations
> of "generic wishful thinking"? Should a paper specifically about a field of
> machine learning *not* call the field by its name? Would a predictive method
> by any other name predict just as well?

In other words, I would expect less marketing and much more science for a paper
in Methods in Ecology and Evolution.

> We do not feel like such a cheap accusation, without any argument to back it
> up, warrants a response. We would expect less aggresive snark and much more
> constructive criticism for a review in Methods in Ecology and Evolution.

Moreover, the main idea of the paper (using node metadata to predict new
interactions using nodes embedding) comes from a paper of the same authors that
is not peer-reviewed and I feel a bit uncomfortable with that (see Strydom et
al. 2021b)

> We do sincerely hope that the fact that this article is now published will
> bring the reviewer comfort.

## Detailed comments

L51: this sentence is a tautological, if interactions are represented by
parameter of bernoulli law, there are already weighted appropriately

> No changes were made - the interactions are weighed appropriately compared to
> the binary baseline, as is the point of the sentence.

L62: ‘machine learning algortihms’ : fancy term but not very specific. What
algorithms are you talking about ?

> The paper cited at the end of this sentence primarily uses artificial neural
> networks, but concludes on the potential to use "data-driven techniques",
> which feels neither less than more specific than our reference to "ML
> algorithms"; as we do spell out in the sentence immediately after this one,
> the core point is that ML algorithms that can be made to generate data have
> the potential to augment data collected through empirical means. No changes
> made to the manuscript.

L78: Botella et al. 2022 does not use node embeddings but network embeddings. In
this case, each point of the low dimension space is a network and not a node.
Consequently, it won’t be useful to predict new potential links. Table 1 is
mixing nodes and network embeddings that do answer to different ecological
questions.

> The fact that Table 1 lists different types of embeddings is self-evident from
> the second column of table 1. Concerning the Botella et al. 2022 paper, the
> reviewer is indeed correct that they use graph embedding. Yet, nowhere do we
> argue that this is relevant to interaction prediction, and instead we
> summarize the findings of this article as the need to evaluate multiple
> embeddings for each problem, as their performance may differ. As all the
> information required was already in the manuscript, no changes were made.

L84: This sentence is too generic. What are machine learning techniques here ?
If you include node embedding in it, it deals with discrete data. Moreover,
there is a broad network science litterature that deals with discrete data.

> The techniques we discuss are listed in the reference given immediately at the
> end of the sentence. There is indeed literature on discrete data (we do not
> make claims to the contrary); our point remains that projecting discrete data
> into a dense, continuous space comes with a list of benefits (that are listed
> in the remainder of this paragraph, together with references to the relevant
> literature). No changes were made.

L129: This sounds a bit superficial and opportunistic. I don't think such a
serious topic can be adequately covered in a short paragraph. Yes, we all know
that machine learning techniques will save the world, thanks.

> We would like to question whether this dismisiveness of our work is
> contributing in a positive way to the discussion that is supposed to take
> place as part of the review process. To be candid, the comments by reviewer 2
> mostly come across as opposed to our work as a matter of principle, but also
> as refusing to take it seriously. We did our best in our response to the
> specific point to not reciprocate, and explained why changes were (or were
> not) made, but we cannot weigh this review equally with Reviewer 1.
> "Superficial", but mostly "opportunistic", are egregious attacks on our
> profesionalism, and insinuate that we did not write the manuscript in good
> faith. They do not deserve a reply, for the should never have been written.

More seriously, we should not forget that these techniques are built by people
and not machines. Consequently, they are also subjects to cultural/national
biases since influencing academic centers are located in the western world.

> We do agree with the reviewer, and this is, in fact, a core point of the
> paragraph, and of most of the articles cited therein. As we are in agreement,
> no changes were made.

L135: I doubt that ‘algorithmic thinking’ is generating new knowledge thanks to
machine learning. Actually, ecological knowledge is generated by people, not
machines. Of course, statistical techniques help scientists to analyze and
structure data. But they must remain tools in the hands of individuals.

> We do agree with the reviewer (but would like to point out that the definition
> of algorithmic thinking we use comes from the article cited immediately before
> we discuss algorithmic thinking). We have added a reference to "algorithm in
> the loop" approaches, alongside their possible issues, and suggestions as to
> the next steps.

L140: But it should also be recognized that these tools, because they can be
difficult to understand for non-specialists, can pose problems of
interpretation. Moreover, they can make those who make decisions dependent on a
tool that they do not master.

> This has been adressed as part of the previous comment, by emphasizing the
> need for training and computational literacy in decision makers.

L145 : Long acknowledgements section for a short paper !

> Not deserving of a response.